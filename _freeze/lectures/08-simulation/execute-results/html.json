{
  "hash": "6929990f32e622a513b1356026834573",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Simulation\"\nauthor: \"<br>SURE 2024<br><br>Department of Statistics & Data Science<br>Carnegie Mellon University\"\nfooter:  \"[36-SURE.github.io/2024](https://36-sure.github.io/2024)\"\nformat:\n  revealjs:\n    theme: theme.scss\n    chalkboard: true\n    smaller: true\n    slide-number: c/t\n    code-line-numbers: false\n    linestretch: 1.25\n    html-math-method:\n      method: mathjax\n      url: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"\n---\n\n\n\n\n\n\n# Background\n\n## Why simulation?\n\n::: columns\n::: {.column width=\"50%\" style=\"text-align: left;\"}\n\n-   We're in the 21st century!\n\n-   Simulations can often be\n\n    -   easier than hand calculations\n\n    -   made more realistic than hand calculations\n\n-   `R` provides unique access to great (statistical) simulation tools (compared to other languages)\n\n:::\n\n::: {.column width=\"50%\" style=\"text-align: left;\"}\n\n![](/images/old-dogs.png){width=\"500\"}\n\n:::\n:::\n\n## Sampling from a given vector\n\n-   To sample from a given vector, use `sample()`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# base R built in English alphabet\n# letters\nsample(letters, size = 5) # sample without replacement, by default\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"r\" \"z\" \"w\" \"f\" \"e\"\n```\n\n\n:::\n\n```{.r .cell-code}\nsample(c(0, 1), size = 7, replace = TRUE) # sample with replacement\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1 1 0 0 0 1 1\n```\n\n\n:::\n\n```{.r .cell-code}\n# 5 (independent) coin tosses\ncoin <- c(\"H\", \"T\")\nsample(coin, 5, replace = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"H\" \"H\" \"T\" \"T\" \"T\"\n```\n\n\n:::\n\n```{.r .cell-code}\nsample(1:100, 1) # sample a random integer between 1 and 100\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 85\n```\n\n\n:::\n:::\n\n\n\n\n## Probability distributions\n\nA distribution is a mathematical function $f(x \\mid \\theta)$ where\n\n-   $x$ may take on continuous or discrete values over the domain (i.e. all possible inputs) of $f(x \\mid \\theta)$\n-   $\\theta$ is a set of parameters governing the shape of the distribution\n    -   e.g. $\\theta = \\{\\mu, \\sigma ^2 \\}$ for a normal (Gaussian) distribution\n-   the $\\mid$ symbol means that the shape of the distribution is conditional on the values of $\\theta$\n\n. . .\n\nLet $f$ denote the distribution for its\n\n-   **probability density function (PDF)** if $x$ is continuous\n-   **probability mass function (PMF)** if $x$ is discrete\n\n. . .\n\nNote:\n\n-   $f(x \\mid \\theta) \\geq 0$ for all $x$\n-   $\\displaystyle \\sum_x f(x \\mid \\theta) = 1$ (discrete case) or $\\displaystyle \\int_x f(x \\mid \\theta) = 1$ (continuous case)\n\n## Normal distribution\n\n::: columns\n::: {.column width=\"50%\" style=\"text-align: left;\"}\n-   PDF: $\\displaystyle f(x \\mid \\mu, \\sigma^2)=\\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^{2}}$; $x \\in (- \\infty, \\infty)$\n\n-   We write $X \\sim N(\\mu, \\sigma^2)$\n\n-   Standard normal distribution: $N(0, 1)$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ntheme_set(theme_light())\ntibble(x = c(-5, 5)) |> \n  ggplot(aes(x)) +\n  stat_function(fun = dnorm, color = \"blue\",\n                args = list(mean = 0, sd = 1)) +\n  stat_function(fun = dnorm, color = \"red\",\n                args = list(mean = -2, sd = sqrt(0.5)))\n```\n:::\n\n\n\n:::\n\n::: {.column width=\"50%\" style=\"text-align: left;\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](08-simulation_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n\n:::\n:::\n\n## Binomial distribution\n\n::: columns\n::: {.column width=\"50%\" style=\"text-align: left;\"}\n\n-   PMF: $\\displaystyle f(x \\mid n, p)= \\binom{n}{x} p^{x}(1-p)^{n-x}$; $x = 0, 1, \\dots, n$\n\n-   Model for the probability of $x$ successes in $n$ independent trials, each with success probability $p$\n\n-   We write $X \\sim \\text{Binomial}(n,p)$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(x = 0:20) |>\n  mutate(binom1 = dbinom(x, size = 20, prob = 0.5),\n         binom2 = dbinom(x, size = 20, prob = 0.1)) |>\n  ggplot(aes(x)) + \n  geom_point(aes(y = binom1), color = \"blue\", size = 4) +\n  geom_point(aes(y = binom2), color = \"red\", size = 4)\n```\n:::\n\n\n\n:::\n\n::: {.column width=\"50%\" style=\"text-align: left;\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](08-simulation_files/figure-revealjs/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n\n\n:::\n:::\n\n## Poisson distribution\n\n::: columns\n::: {.column width=\"50%\" style=\"text-align: left;\"}\n-   PMF: $\\displaystyle f(x \\mid \\lambda)= \\frac{ e^{-\\lambda} \\lambda^x}{x!}$; $x = 0, 1, 2, \\dots$ and $\\lambda > 0$\n\n-   Model for the counts of an event in a fixed period of time, with a rate of occurrence parameter $\\lambda$\n\n-   We write $X \\sim \\text{Poisson}(\\lambda)$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(x = 0:10) |> \n  mutate(y = dpois(x, 1)) |> \n  ggplot(aes(x, y)) +\n  geom_point(size = 4)\n```\n:::\n\n\n\n:::\n\n::: {.column width=\"50%\" style=\"text-align: left;\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](08-simulation_files/figure-revealjs/unnamed-chunk-8-1.png){width=960}\n:::\n:::\n\n\n\n:::\n:::\n\n## Random number generation\n\nExample: Sampling from a normal distribution\n\n-   `rnorm()`: generate normal random variables\n\n-   `pnorm()`: normal cumulative distribution function\n\n-   `dnorm()`: normal density function\n\n-   `qnorm()`: normal quantile function\n\n. . .\n\nNote: Replace \"norm\" with the name of another distribution, all the same functions apply.\n\n-   E.g., \"t\", \"exp\", \"gamma\", \"chisq\", \"binom\", \"pois\", \"unif\", etc.\n\nSee [this manual](https://rstudio.github.io/r-manuals/r-intro/Probability-distributions.html) for more details\n\n## Random number generation\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# these are the defaults for mean and sd\nz <- rnorm(1000, mean = 0, sd = 1)\n# check: the sample mean is approximately 0\nmean(z) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.007982799\n```\n\n\n:::\n\n```{.r .cell-code}\n# check: the sample sd is approximately 1\nsd(z)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.013261\n```\n\n\n:::\n:::\n\n\n\n\n## Revisiting ECDF\n\nRecall that we can use the ECDF to estimate the true cumulative distribution function\n\n::: columns\n::: {.column width=\"50%\" style=\"text-align: left;\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nz_ecdf <- ecdf(z)\nz_ecdf(0) # should get close to 1/2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.489\n```\n\n\n:::\n\n```{.r .cell-code}\nclass(z_ecdf)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"ecdf\"     \"stepfun\"  \"function\"\n```\n\n\n:::\n\n```{.r .cell-code}\nnormal_tbl <- tibble(z = sort(z)) |> \n  mutate(empirical = z_ecdf(z),\n         true = pnorm(z))\nnormal_tbl\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,000 × 3\n       z empirical     true\n   <dbl>     <dbl>    <dbl>\n 1 -3.11     0.001 0.000945\n 2 -3.10     0.002 0.000967\n 3 -2.96     0.003 0.00152 \n 4 -2.68     0.004 0.00363 \n 5 -2.57     0.005 0.00505 \n 6 -2.57     0.006 0.00508 \n 7 -2.50     0.007 0.00613 \n 8 -2.49     0.008 0.00644 \n 9 -2.37     0.009 0.00900 \n10 -2.31     0.01  0.0104  \n# ℹ 990 more rows\n```\n\n\n:::\n:::\n\n\n\n:::\n\n::: {.column width=\"50%\" style=\"text-align: left;\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnormal_tbl |> \n  pivot_longer(!z, \n               names_to = \"method\", \n               values_to = \"val\") |> \n  ggplot(aes(x = z, y = val, color = method)) +\n  geom_line()\n```\n\n::: {.cell-output-display}\n![](08-simulation_files/figure-revealjs/unnamed-chunk-11-1.png){width=960}\n:::\n:::\n\n\n\n:::\n:::\n\n## Stick breaking problem\n\nIf a stick of unit length is broken in two at random, what is the average ratio of the smaller length to the larger?\n\n. . .\n\nFirst... any guesses? (Also, any guess on what the average length of the smaller (or larger) piece is?)\n\n. . .\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- runif(10000)\nsmaller <- ifelse(x < 0.5, x, 1 - x)\nratio <- smaller / (1 - smaller)\n# get a distribution\n# hist(ratio)\nmean(ratio) # exact answer: 2 * log(2) - 1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.3852437\n```\n\n\n:::\n:::\n\n\n\n\n. . .\n\nHow would you do this by hand...?\n\n<!-- All points of the stick are equally likely to be a breaking point -->\n\n<!-- The breaking point is equally likely to be in the left half and the right half -->\n\n<!-- Suppose the point fell in the right half -->\n\n<!-- The desired fraction is $(1 - x) / x$ -->\n\n<!-- Since x is evenly distributed from 1/2 to 1 -->\n\n<!-- the average value is $2 \\int_{1/2}^1 \\frac{1-x}{x}$ -->\n\n## Estimating $\\pi$ using Monte Carlo simulation\n\n-   [Monte Carlo methods](https://en.wikipedia.org/wiki/Monte_Carlo_method) rely on repeated random sampling to obtain numerical results\n\n-   Use randomness to solve problems that might be deterministic in principle\n\n. . .\n\n-   Example: Estimating $\\pi$\n\n    -   Simulate random $(x, y)$ points with domain as a square of side $2r$ units centered at the origin\n\n    -   Consider a circle inside the same domain with same radius $r$ and inscribed into the square\n\n    -   Calculate the ratio of number points inside the circle and total number of generated points (Why?)\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n## Estimating $\\pi$ using Monte Carlo simulation\n\n::: columns\n::: {.column width=\"50%\" style=\"text-align: left;\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_points <- 10000\nx <- runif(n_points, -1, 1)\ny <- runif(n_points, -1, 1)\ninside <- ifelse(x^2 + y^2 <= 1, 1, 0)\n4 * mean(inside)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3.1444\n```\n\n\n:::\n:::\n\n\n\n:::\n\n::: {.column width=\"50%\" style=\"text-align: left;\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(x, y, inside) |> \n  ggplot(aes(x, y, color = factor(inside))) +\n  geom_point(show.legend = FALSE) +\n  coord_equal()\n```\n\n::: {.cell-output-display}\n![](08-simulation_files/figure-revealjs/unnamed-chunk-15-1.png){width=960}\n:::\n:::\n\n\n\n:::\n:::\n\n# Pseudorandomness and seeds\n\n## Same command, different results?\n\nNot surprisingly, we get different sample draws each time we call `rnorm()`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(rnorm(100))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.08671752\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(rnorm(100))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1367164\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(rnorm(100))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.01806964\n```\n\n\n:::\n:::\n\n\n\n\n## Is it really random?\n\n::: columns\n::: {.column width=\"50%\" style=\"text-align: left;\"}\n\n<br>\n\nRandom numbers generated in `R` (or any language) are not truly random; they are what we call **pseudorandom**\n\n-   These are numbers generated by computer algorithms that very closely mimick truly random numbers\n\n-   The default algorithm in `R` is called the Mersenne Twister\n\n:::\n\n::: {.column width=\"50%\" style=\"text-align: left;\"}\n\n![](/images/wendys.png){width=\"400\"}\n\n:::\n:::\n\n::: aside\nTo learn more, type `?Random` into `R` (check out how to change the algorithm used for pseudorandom number generation, which you should never really have to do...)\n:::\n\n\n\n## Setting the random seed\n\n-   All pseudorandom number generators depend on what is called a **seed** value\n\n-   This puts the random number generator in a well-defined *state*, so that the numbers it generates, from then on, will be reproducible\n\n-   The seed is just an integer, and can be set with `set.seed()`\n\n-   The reason we set it: so that when someone else runs our simulation code, they can see the same—albeit, still random—results that we do\n\n-   Note: `set.seed()` will be helpful later on for things like cross-validation, $k$-means clustering, etc. --- basically anything that involves randomly sampling of the data\n\n## Setting the random seed\n\nSame seed, same results\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1999)\nrnorm(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  0.73267249 -0.03782971  1.20300914\n```\n\n\n:::\n\n```{.r .cell-code}\nset.seed(1999)\nrnorm(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  0.73267249 -0.03782971  1.20300914\n```\n\n\n:::\n\n```{.r .cell-code}\nset.seed(1999)\nrnorm(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  0.73267249 -0.03782971  1.20300914\n```\n\n\n:::\n:::\n\n\n\n\n# Iteration and simulation\n\n## Example: drug effect model\n\nSuppose we have a model for the way a drug affected certain patients\n\n-   All patients will undergo chemotherapy. We believe those who aren’t given the drug experience a reduction in tumor size of percentage $X_{\\mathrm{no\\,drug}} \\sim 100 \\cdot \\mathrm{Exponential}(R)$, where $R \\sim \\mathrm{Uniform}(0,1)$\n\n-   And those who were given the drug experience a reduction in tumor size of percentage $X_{\\mathrm{drug}} \\sim 100 \\cdot \\mathrm{Exp}(2)$\n\n. . .\n\nSuppose some scientist collaborators are wondering how many patients would we need to have in each group (drug, no drug), in order to reliably see that the average reduction in tumor size is large...\n\nWhat would you do?\n\n-   Before: get out your pen and paper, make some approximations\n-   Now: just simulate from the model, no approximations\n\n## Example: drug effect model\n\n::: columns\n::: {.column width=\"50%\" style=\"text-align: left;\"}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# suppose each group has 50 subjects\nset.seed(100)\nn_subjects <- 50 \nmean_drug <- 2\nmean_nodrug <- runif(n_subjects, 0, 1)\nx_drug <- 100 * rexp(n_subjects, 1 / mean_drug) \nx_nodrug <- 100 * rexp(n_subjects, 1 / mean_nodrug)\n\ntibble(x_drug, x_nodrug) |> \n  pivot_longer(everything(),\n               names_to = \"group\",\n               names_prefix = \"x_\",\n               values_to = \"reduction\") |> \n  ggplot(aes(x = reduction, y = after_stat(density), \n             color = group)) +\n  geom_histogram(aes(fill = group), \n                 alpha = 0.5, color = \"black\",\n                 position = \"identity\") +\n  geom_density(aes(color = group))\n```\n:::\n\n\n\n\n:::\n\n\n::: {.column width=\"50%\" style=\"text-align: left;\"}\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](08-simulation_files/figure-revealjs/unnamed-chunk-19-1.png){width=960}\n:::\n:::\n\n\n\n\n\n\n:::\n:::\n\n\n# Good practices\n\n## Repetition and reproducibility\n\n-   One single simulation is not always trustworthy (depends on the situation, of course)\n\n-   In general, simulations should be repeated and aggregate results reported --- requires iteration!\n\n-   To make random number draws reproducible, we must set the seed with `set.seed()`\n\n-   More than this, to make simulation results reproducible, we need to follow **good programming practices** (see [this](https://36-750.github.io/practices/best-practices/) for example)\n\n-   Gold standard: any time you show a simulation result (a figure, a table, etc.), you have code that can be run (by anyone) to produce exactly the same result\n\n## Iteration and simulation\n\n-   Writing a function to complete a single run of your simulation/analysis is often very helpful\n\n-   This allows the simulation itself to be intricate (e.g., intricate steps, several simulation parameters), but makes running the simulation simple\n\n-   Then you can use iteration to run your simulation/analysis over and over again\n\n## Iteration and simulation\n\nExample: Revisiting $k$-means clustering with `gapminder` data - compute the total within-cluster variation for different values of $k$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dslabs)\nclean_gapminder <- gapminder |>\n  filter(year == 2011, !is.na(gdp)) |>\n  mutate(std_log_gdp = as.numeric(scale(log(gdp), center = TRUE, scale = TRUE)),\n         std_life_exp = as.numeric(scale(life_expectancy, center = TRUE, scale = TRUE)))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# function to perform clustering for each value of k\ngapminder_kmeans <- function(k) {\n  kmeans_results <- clean_gapminder |>\n    select(std_log_gdp, std_life_exp) |>\n    kmeans(centers = k, nstart = 30)\n  \n  kmeans_out <- tibble(clusters = k,\n                       total_wss = kmeans_results$tot.withinss)\n  return(kmeans_out)\n}\n\n# number of clusters to search over\nn_clusters_search <- 2:12\n\n# iterate over each cluster value to compute total wss\nkmeans_search <- n_clusters_search |> \n  map(gapminder_kmeans) |> \n  bind_rows()\n```\n:::\n\n\n\n\n## Pre-allocation\n\nExample: When 100 coins are tossed, what is the probability that exactly 50 are heads?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tictoc)\nn_runs <- 500000\na <- c()\ntic()\nfor (i in 1:n_runs) {\n  tosses <- sample(0:1, size = 100, replace = TRUE)\n  a[i] <- sum(tosses)\n}\ntoc()\n\nb <- rep(NA, n_runs)\ntic()\nfor (i in 1:n_runs) {\n  tosses <- sample(0:1, size = 100, replace = TRUE)\n  b[i] <- sum(tosses)\n}\ntoc()\n\n# exact: (factorial(100) / (factorial(50) * factorial(50))) * (1 / 2) ^ 100\nmean(b == 50)\n```\n:::\n\n\n\n\n## Pre-allocation\n\n::: columns\n::: {.column width=\"50%\" style=\"text-align: left;\"}\n\n* Not only computations take time, memory allocations do too\n\n* Changing the size of a vector takes just about as long as creating a new vector does\n\n* Each time the size changes, R needs to reconsider its allocation of memory to the object\n\n* Never reallocate a vector after each iteration\n\n:::\n\n::: {.column width=\"50%\" style=\"text-align: left;\"}\n\n[Analogy](https://privefl.github.io/advr38book/performance.html)\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](https://privefl.github.io/blog/images/stairs.jpg){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n:::\n\n:::\n\n# Exporting and importing data\n\n## Reading/writing from/to a file\n\nSometimes simulations/analyses take a long time to run, and we want to save intermediate or final output, for quick reference later\n\nIntroducing the `readr` package (part of `tidyverse`; automatically loaded)\n\n-   `write_*()` functions: exporting data\n\n-   `read_*()` functions: importing data\n\n## Reading/writing from/to a file\n\n-   `write_csv()` / `read_csv()`: export / import single `R` data frames or tibbles in `.csv` format\n\n-   `write_rds()` / `read_rds()`: export / import single `R` objects (like a vector, matrix, list, data frame, etc.) in `.rds` format\n\nNote that by default, the file will be written to the working directory (i.e. if you just specify the file name)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexample_df <- tibble(x = rnorm(100), y = rnorm(100))\nwrite_rds(example_df, \"INSERT PATH/example_df.csv\")\ndf <- read_csv(\"INSERT PATH/example_df.csv\")\n\nexample_obj <- matrix(rnorm(25), 5, 5)\nwrite_rds(example_obj, \"INSERT PATH/example_obj.rds\")\nobj <- read_rds(\"INSERT PATH/example_obj.rds\")\n```\n:::\n\n\n\n\nExample: saving $k$-means clustering results from earlier\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# saving to a folder named \"data\" in the working directory\nwrite_csv(kmeans_search, \"data/kmeans_search_results.csv\")\n```\n:::\n\n\n\n\n## File path and working directory\n\n-   To read in a file, you need to use the correct path, which should be relative and NOT absolute (or a path pointing to a location outside of the project directory) (read more [here](https://en.wikipedia.org/wiki/Path_(computing)))\n\n-   The key to getting paths to work is to understand working directory. In `R`, use the function `getwd()`\n\n    -   Note: NEVER use `setwd()` to change working directory. It's a bad practice. ([Here's why](https://github.com/jennybc/here_here))\n    \n## File path and working directory    \n\n-   Special paths\n\n    -   `.` is the working directory\n\n    -   `~` is the home directory (e.g., on Quang's laptop: `/Users/qntkhvn`)\n\n    -   `..` is the parent directory. (e.g., `../steve.csv` refers to a file called `steve.csv` in the directory that is one level above the working directory)\n\n-   Common issue: By default, the working directory for an R Markdown or Quarto document is the directory in which that document is stored. This is NOT necessarily the working directory of your current `R` session.\n\n-   Use `list.files()` to see what files are available in the working directory (or any other directory)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlist.files()\nlist.files(\"~\")\n```\n:::\n\n\n\n\n## Resources\n\n-   [`here` package](https://here.r-lib.org/)\n\n-   [`fertile` package](https://arxiv.org/pdf/2008.12098)\n\n-   [What They Forgot to Teach You About `R`](https://rstats.wtf/)\n\n## In reality...\n\n![](/images/code-advice.jpeg){width=\"300\"}\n\n\n<!-- (Exercise 5 https://beanumber.github.io/sds192/lab-import.html) -->\n\n<!-- ## Data -->\n\n<!-- New York City Airbnb -->\n\n<!-- ```{r} -->\n\n<!-- library(tidyverse) -->\n\n<!-- theme_set(theme_light()) -->\n\n<!-- ``` -->\n\n<!-- ```{r} -->\n\n<!-- #| echo: false -->\n\n<!-- ggplot2::theme_set(ggplot2::theme_light(base_size = 20)) -->\n\n<!-- ``` -->\n\n<!-- ::: columns -->\n\n<!-- ::: {.column width=\"50%\" style=\"text-align: left;\"} -->\n\n<!-- c1 -->\n\n<!-- ::: -->\n\n<!-- ::: {.column width=\"50%\" style=\"text-align: left;\"} -->\n\n<!-- c2 -->\n\n<!-- ::: -->\n\n<!-- ::: -->",
    "supporting": [
      "08-simulation_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}