{
  "hash": "626c4239e57399941b6b6a5961b7fae6",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Supervised learning: generalized linear models\"\nauthor: \"<br>SURE 2024<br><br>Department of Statistics & Data Science<br>Carnegie Mellon University\"\nfooter:  \"[36-SURE.github.io](https://36-sure.github.io)\"\nformat:\n  revealjs:\n    theme: theme.scss\n    chalkboard: true\n    smaller: true\n    slide-number: c/t\n    code-line-numbers: false\n    linestretch: 1.25\n    html-math-method:\n      method: mathjax\n      url: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"\n---\n\n\n\n\n\n\n# Background\n\n## Recap\n\n* When the response is continuous, we can use linear regression \n\n* When the response is binary categorical, we can use logistic regression\n\n* Which model do we use if the response contains discrete counts?\n\n## Generalized linear models (GLMs)\n\nThree components of a GLM\n\n**1. Random component (distribution of the response)**\n\n*   Identifies the response variable and assumes a probability distribution for it\n\n. . .\n\n**2. Linear predictor**\n\n*   Specifies the predictor variables\n  \n*   Linear combination of predictors on the right-hand side of the model equation\n  \n*   In the form $\\beta_0 + \\beta_1 X_1 + \\dots + \\beta_p X_p$\n\n. . .\n\n**3. Link function (a function of the parameter)**\n\n*   Connects the random component with the linear predictor\n\n*   Via a function of the expected value of the probability distribution of the response\n\nSee also: [Exponential family](https://en.wikipedia.org/wiki/Exponential_family)\n\n## Linear regression\n\n1. $Y \\sim N(\\mu, \\sigma ^2)$\n\n2. Linear predictor: $\\beta_0 + \\beta_1 X_1 + \\dots + \\beta_p X_p$\n\n3. Identity link function: $g(\\mu) = \\mu$\n\n## Logistic regression\n\n1. $Y \\sim \\text{Binomial}(n,p)$\n\n2. Linear predictor: $\\beta_0 + \\beta_1 X_1 + \\dots + \\beta_p X_p$\n\n3. Logit link function: $\\displaystyle g(p) = \\log\\left(\\frac{p}{1-p}\\right)$\n\n(Recall: We cannot just simply model $p = \\beta_0 + \\beta_1 X_1 + \\dots + \\beta_p X_p$, since the binary response can only take on values of either 0 or 1)\n\n## Poisson regression\n\n1. $Y \\sim \\text{Poisson}(\\lambda)$\n\n2. Linear predictor: $\\beta_0 + \\beta_1 X_1 + \\dots + \\beta_p X_p$\n\n3. Log link function: $\\displaystyle g(\\lambda) = \\log (\\lambda)$\n\n(We cannot just simply model $\\lambda = \\beta_0 + \\beta_1 X_1 + \\dots + \\beta_p X_p$, since the counts can only take on non-negative integers)\n\n## Generalization example\n\nIn linear regression, the distribution is normal and the domain of $Y \\mid x$ is $(-\\infty,\\infty)$\n\n. . .\n\nWhat, however, happens if we know that\n\n* the domain of observed values of the response is actually $[0,\\infty]$\n\n* the observed values are __discrete__, with possible values $0, 1, 2, \\dots$\n\n\n. . .\n\n__The normal distribution doesn't hold here__\n\n- Which distribution could possibly govern $Y \\mid x$?\n\n- Remember, we might not know truly how $Y \\mid x$ is distributed, but any assumption we make has to fit with the nature of the data\n\n---\n\n## Generalization: Poisson regression\n\n-   PMF of a Poisson distribution: $\\displaystyle f(x \\mid \\lambda)= \\frac{ e^{-\\lambda} \\lambda^x}{x!}$; $x = 0, 1, 2, \\dots$ and $\\lambda > 0$\n\n. . .\n\n- Model for the counts of an event in a fixed period of time or space, with a rate of occurrence parameter $\\lambda$\n\n- $\\lambda$ is __both__ the mean and the variance of the distribution\n\n  - in general, the variance governs the distribution's shape\n\n. . .\n\n- distribution of independent event occurences in an interval, e.g. soccer goals in a match\n\n- $\\lambda$ is the average number of the events in an interval\n\n. . .\n\nSo, when we apply GLM in this context, we would identify the family as Poisson\n\nBut there's another step in generalization...\n\n## Generalization: link function\n\nStart with one predictor, linear function: $\\beta_0 + \\beta_1 x$\n\n. . .\n\nRange of this function: $(-\\infty,\\infty)$\n\nBut for Poisson regression, $Y$ __cannot be negative__,\n\n- __We need to transform the linear function__ to be $[0,\\infty)$ \n\n  -   (What if we use linear regression? Results may not be meaningful, e.g., we predict ${\\hat Y}$ to be negative!)\n\n. . .\n\n__There is usually no unique transformation__, but rather conventional ones\n\n## Generalization: link function\n\nFor Poisson, we use the $\\log()$ function as the __link function__ $g()$:\n\n$$g(\\lambda \\mid x) = \\log(\\lambda \\mid x) = \\beta_0 + \\beta_1 x$$\n\n\n(Hence we also call this a [log-linear model](https://en.wikipedia.org/wiki/Log-linear_model))\n\n. . .\n\nGiven $Y$ with values limited to being either 0 or positive integers, with no upper bound, we\n\n1. assume $Y \\mid x \\sim \\text{Poisson}(\\lambda)$\n\n2. assume $\\lambda \\mid x = e^{\\beta_0 + \\beta_1 x}$ \n\n3. use optimization to estimate $\\beta_0$ and $\\beta_1$ by maximizing the likelihood function\n\n\n## More distributions\n\n[Gamma distribution](https://en.wikipedia.org/wiki/Gamma_distribution)\n\n+ $Y \\mid x$ continuous, but bounded between 0 and $\\infty$\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e6/Gamma_distribution_pdf.svg/650px-Gamma_distribution_pdf.svg.png){fig-align='center' width=50%}\n:::\n:::\n\n\n\n\n## More distributions\n\n[Beta distribution](https://en.wikipedia.org/wiki/Beta_distribution)\n\n+ $Y \\mid x$ continuous, but bounded between 0 and 1\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](https://upload.wikimedia.org/wikipedia/commons/thumb/f/f3/Beta_distribution_pdf.svg/650px-Beta_distribution_pdf.svg.png){fig-align='center' width=50%}\n:::\n:::\n\n\n\n\n## More distributions\n\n[Bernoulli distribution](https://en.wikipedia.org/wiki/Bernoulli_distribution)\n\n+ $Y \\mid x$ discrete, but can only take on the values 0 and 1\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Bernoulli_Distribution.PNG/650px-Bernoulli_Distribution.PNG){fig-align='center' width=50%}\n:::\n:::\n\n\n\n\n## Modeling count data\n\nGoals scored across men’s soccer matches in the five biggest European leagues during the 2023-2024 season, via the [worldfootballR](https://jaseziv.github.io/worldfootballR) package\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ntheme_set(theme_light())\ngoals <- read_csv(\"https://raw.githubusercontent.com/36-SURE/36-SURE.github.io/main/data/goals.csv\")\nglimpse(goals)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 3,504\nColumns: 7\n$ n_goals  <dbl> 0, 2, 0, 0, 4, 1, 5, 2, 1, 1, 1, 0, 2, 5, 2, 0, 3, 1, 3, 0, 0…\n$ xG       <dbl> 0.3, 0.8, 2.7, 0.5, 4.0, 1.3, 3.3, 2.2, 1.4, 2.2, 0.6, 1.9, 1…\n$ off_team <chr> \"Burnley\", \"Arsenal\", \"Everton\", \"Sheffield Utd\", \"Brighton\",…\n$ def_team <chr> \"Manchester City\", \"Nott'ham Forest\", \"Fulham\", \"Crystal Pala…\n$ league   <chr> \"ENG\", \"ENG\", \"ENG\", \"ENG\", \"ENG\", \"ENG\", \"ENG\", \"ENG\", \"ENG\"…\n$ match_id <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…\n$ is_home  <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n```\n\n\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\n## EDA: Distribution for the number of goals\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngoals |> \n  count(n_goals) |> \n  ggplot(aes(n_goals, n)) +\n  geom_col(width = 0.5) +\n  scale_x_continuous(breaks = 0:8)\n```\n\n::: {.cell-output-display}\n![](15-glm_files/figure-revealjs/unnamed-chunk-7-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n\n## EDA: Distribution for the number of goals by league\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngoals |> \n  count(n_goals, league) |> \n  ggplot(aes(n_goals, n)) +\n  geom_col(width = 0.5) +\n  scale_x_continuous(breaks = 0:8) +\n  facet_wrap(~ league, nrow = 1)\n```\n\n::: {.cell-output-display}\n![](15-glm_files/figure-revealjs/unnamed-chunk-8-1.png){fig-align='center' width=1728}\n:::\n:::\n\n\n\n\n## EDA: Distribution for the number of goals by home/away team\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngoals |> \n  count(n_goals, is_home) |> \n  mutate(is_home = factor(is_home)) |> \n  ggplot(aes(n_goals, n, fill = is_home, group = is_home)) +\n  geom_col(position = \"dodge\", width = 0.5) +\n  scale_x_continuous(breaks = 0:8)\n```\n\n::: {.cell-output-display}\n![](15-glm_files/figure-revealjs/unnamed-chunk-9-1.png){fig-align='center' width=1440}\n:::\n:::\n\n\n\n\n## Fitting a poisson regression model\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngoals_poisson <- glm(n_goals ~ league + is_home, \n                     family = \"poisson\",\n                     data = goals)\n# summary(goals_poisson)\nlibrary(broom)\ntidy(goals_poisson)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)   0.385     0.0323    11.9   1.18e-32\n2 leagueESP    -0.215     0.0424    -5.07  3.98e- 7\n3 leagueFRA    -0.195     0.0449    -4.34  1.46e- 5\n4 leagueGER    -0.0185    0.0426    -0.433 6.65e- 1\n5 leagueITA    -0.228     0.0426    -5.36  8.44e- 8\n6 is_home       0.208     0.0283     7.36  1.87e-13\n```\n\n\n:::\n:::\n\n\n\n\nWhat observations in the dataset correspond to predictions using only the intercept?\n\n## Fitting a poisson regression model\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntidy(goals_poisson, exponentiate = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)    1.47     0.0323    11.9   1.18e-32\n2 leagueESP      0.807    0.0424    -5.07  3.98e- 7\n3 leagueFRA      0.823    0.0449    -4.34  1.46e- 5\n4 leagueGER      0.982    0.0426    -0.433 6.65e- 1\n5 leagueITA      0.796    0.0426    -5.36  8.44e- 8\n6 is_home        1.23     0.0283     7.36  1.87e-13\n```\n\n\n:::\n:::\n\n\n\n\nWe have sufficient evidence to suggest the expected number of goals is different between ENG teams and each of ESP, FRA, and ITA, but not GER, after accounting for home field advantage\n\nThe expected number of goals changes (is multiplied) by a factor of 1.27 if the team is home in comparison to away teams, after accounting for league\n\n## Model residuals and goodness-of-fit measures \n\n*   Pearson residuals: $\\displaystyle r_i = \\frac{y_i-\\hat{\\lambda}_i}{\\sqrt{\\hat{\\lambda}_i}}$\n*   Deviance residuals: $\\displaystyle d_i = \\textrm{sign}(y_i-\\hat{\\lambda}_i) \\sqrt{2 \\left[y_i \\log\\left(\\frac{y_i}{\\hat{\\lambda}_i}\\right) -(y_i - \\hat{\\lambda}_i) \\right]}$\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nresiduals(goals_poisson, type = \"pearson\")\nresiduals(goals_poisson, type = \"deviance\")\n```\n:::\n\n\n\n\n*   Model summaries\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nglance(goals_poisson)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 8\n  null.deviance df.null logLik    AIC    BIC deviance df.residual  nobs\n          <dbl>   <int>  <dbl>  <dbl>  <dbl>    <dbl>       <int> <int>\n1         4379.    3503 -5363. 10738. 10775.    4272.        3498  3504\n```\n\n\n:::\n:::\n\n\n\n\n**As before, we prefer assessment in terms of out-of-sample/test set performances over these measures**\n\n## Overdispersion\n\n* Overdispersion is a common problem faced in Poisson regression when the variance is larger than what is assumed under the model\n\n* Recall that a Poisson distribution assumes equidispersion (i.e. the mean and variance are equal)\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nvar(goals$n_goals)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.58617\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(goals$n_goals)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.442352\n```\n\n\n:::\n:::\n\n\n\n\n* Looks like overdispersion is not a concern here\n\n## Quasipoisson regression\n\nIn the case of overdispersion (the variance is larger than expected), the resulting standard errors of the model coefficients can be inflated by the dispersion parameter $$\\displaystyle \\varphi = \\frac{\\sum_{i} r_i^2}{n - p},$$ where $p$ is the number of model parameters, and $r_i$ is the Pearson residual for the $i$th observation\n\nWe can then multiply each coefficient standard error by $\\varphi$\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsum(residuals(goals_poisson, type = \"pearson\") ^ 2) / df.residual(goals_poisson)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.070286\n```\n\n\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngoals_qp <- glm(n_goals ~ league + is_home, \n                family = \"quasipoisson\",\n                data = goals)\n# summary(goals_qp)\n# goals_qp |> \n#   glance() |> \n#   summarize(p_val = pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))\n```\n:::\n\n\n\n\n\n## Negative binomial regression\n\nKey idea: introduces another parameter such that the variance can exceed the mean\n\n. . .\n\nWe have $E(Y)  = \\lambda$ and $\\text{Var}(Y)=\\lambda(1+\\alpha \\lambda)$\n\n. . .\n\n* The variance is still proportional to $\\lambda$, but depends on the dispersion parameter $\\alpha \\ge 0$\n\n. . .\n\n* The further $\\alpha$ falls above 0, the greater the overdispersion relative to Poisson variability\n\n. . .\n\n* As $\\alpha$ decreases toward 0, the variance decreases toward $\\lambda$ , and the model converges to a Poisson distribution\n\n. . .\n\nSee [here](https://bookdown.org/roback/bookdown-BeyondMLR/ch-poissonreg.html#negative-binomial-modeling) for more information\n\n## Negative binomial regression\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngoals_nb <- MASS::glm.nb(n_goals ~ league + is_home, data = goals)\nsummary(goals_nb)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nMASS::glm.nb(formula = n_goals ~ league + is_home, data = goals, \n    init.theta = 21.53331101, link = log)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  0.38498    0.03348  11.500  < 2e-16 ***\nleagueESP   -0.21511    0.04383  -4.908 9.22e-07 ***\nleagueFRA   -0.19437    0.04638  -4.190 2.78e-05 ***\nleagueGER   -0.01865    0.04423  -0.422    0.673    \nleagueITA   -0.22798    0.04398  -5.184 2.17e-07 ***\nis_home      0.20807    0.02922   7.122 1.07e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(21.5333) family taken to be 1)\n\n    Null deviance: 4141.0  on 3503  degrees of freedom\nResidual deviance: 4040.6  on 3498  degrees of freedom\nAIC: 10732\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  21.53 \n          Std. Err.:  8.31 \n\n 2 x log-likelihood:  -10718.22 \n```\n\n\n:::\n:::\n\n\n\n\n## Zero-inflated Poisson regression\n\n*   One common problem in modeling count data is the prevalence of zeros\n\n*   While the Poisson distribution allows for zero counts, there are problems with a lot more zeros observed than expected for Poisson data\n\n. . .\n\n*   A **zero-inflated Poisson (ZIP) model** is a mixture model with two components\n\n    *   Logistic regression model to predict whether the response will be zero (whether 0 goals are observed) $$P(Y = 0) = \\pi + (1 - \\pi)e^{\\lambda}$$\n\n    *   Poisson regression model for non-zero counts (non-zero goal values) $$P(Y = y) = (1 - \\pi) \\frac{\\lambda^y e^{-\\lambda}}{y!}, \\text{\nfor } y = 1, 2, 3, \\dots$$\n    \n\n## Zero-inflated Poisson (ZIP) regression\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(pscl) # install.packages(\"pscl\")\ngoals_zip <- zeroinfl(n_goals ~ league + is_home, data = goals)\nsummary(goals_zip)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nzeroinfl(formula = n_goals ~ league + is_home, data = goals)\n\nPearson residuals:\n    Min      1Q  Median      3Q     Max \n-1.3289 -1.0266 -0.1845  0.7004  5.2685 \n\nCount model coefficients (poisson with log link):\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  0.41532    0.04103  10.123  < 2e-16 ***\nleagueESP   -0.17010    0.05467  -3.111  0.00186 ** \nleagueFRA   -0.18004    0.05792  -3.108  0.00188 ** \nleagueGER   -0.01636    0.05351  -0.306  0.75985    \nleagueITA   -0.22493    0.05737  -3.921 8.82e-05 ***\nis_home      0.18472    0.03752   4.923 8.53e-07 ***\n\nZero-inflation model coefficients (binomial with logit link):\n            Estimate Std. Error z value Pr(>|z|)   \n(Intercept)  -3.6716     1.2681  -2.895  0.00379 **\nleagueESP     1.3000     1.3596   0.956  0.33902   \nleagueFRA     0.6130     1.6018   0.383  0.70195   \nleagueGER     0.1166     1.7986   0.065  0.94831   \nleagueITA     0.1689     2.0463   0.083  0.93421   \nis_home      -0.8116     0.9188  -0.883  0.37709   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nNumber of iterations in BFGS optimization: 40 \nLog-likelihood: -5359 on 12 Df\n```\n\n\n:::\n:::\n\n\n\n\n## Model selection: Poisson vs ZIP\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(2008)\nn_folds <- 5\ngoals_folds <- goals |> \n  distinct(match_id) |>\n  mutate(match_fold = sample(rep(1:n_folds, length.out = n())))\n\n# goals_folds |> count(match_fold)\n\ngoals <- goals |> \n  left_join(goals_folds, by = \"match_id\")\n```\n:::\n\n\n\n\n\n## Cross-validation\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npoisson_cv <- function(k) {\n\n  train_goals <- goals |> \n    filter(match_fold != k)\n  test_goals <- goals |> \n    filter(match_fold == k)\n\n  poisson_fit <- glm(n_goals ~ league + is_home, family = \"poisson\", data = train_goals)\n  poisson_test_preds <- predict(poisson_fit, newdata = test_goals, type = \"response\")\n  \n  # return a table with RMSE and fold id\n  poisson_out <- tibble(rmse = sqrt(mean((test_goals$n_goals - poisson_test_preds) ^ 2)), \n                        match_fold = k)\n  return(poisson_out)\n}\n\npoisson_cv_results <- map(1:n_folds, poisson_cv) |> \n  list_rbind()\n```\n:::\n\n\n\n\n## Cross-validation\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nzip_cv <- function(k) {\n\n  train_goals <- goals |> \n    filter(match_fold != k)\n  test_goals <- goals |> \n    filter(match_fold == k)\n  \n  zip_fit <- zeroinfl(n_goals ~ league + is_home, data = train_goals)\n  zip_test_preds <- predict(zip_fit, newdata = test_goals)\n  \n  zip_out <- tibble(rmse = sqrt(mean((test_goals$n_goals - zip_test_preds)^2)),\n                    match_fold = k)\n  return(zip_out)\n}\n\nzip_cv_results <- map(1:n_folds, zip_cv) |> \n  list_rbind()\n```\n:::\n\n\n\n\n## Out-of-sample comparison\n\nWhich model would you select?\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npoisson_cv_results |> \n  summarize(avg_rmse = mean(rmse))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 1\n  avg_rmse\n     <dbl>\n1     1.24\n```\n\n\n:::\n\n```{.r .cell-code}\nzip_cv_results |> \n  summarize(avg_rmse = mean(rmse))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 1\n  avg_rmse\n     <dbl>\n1     1.24\n```\n\n\n:::\n:::\n\n\n\n\n. . .\n\nRemember: [Occam's razor](https://en.wikipedia.org/wiki/Occam%27s_razor)\n\n## Resources\n\n*   [Bivariate Poisson regression](https://doi.org/10.1111/1467-9884.00366)\n\n*   [Generalized Poisson regression](https://doi.org/10.1080/03610929208830766)\n\n*   [Skellam regression](https://arxiv.org/pdf/1807.07536)\n\n*   [Conway-Maxwell-Poisson regression](https://doi.org/10.1007/s11222-023-10244-0)\n\n*   Poisson–Tweedie regression\n\n\n## Appendix: Code to build dataset\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(worldfootballR)\nlibrary(tidyverse)\nbig5 <- fb_match_results(country = c(\"ENG\", \"ESP\", \"ITA\", \"GER\", \"FRA\"),\n                         gender = \"M\", \n                         season_end_year = 2024, \n                         tier = \"1st\")\nbig5 <- big5 |>\n  mutate(match_id = row_number()) |>  # add unique id for each row\n  filter(!is.na(Wk))\n  \nhome_goals <- big5 |>\n  select(n_goals = HomeGoals, xG = Home_xG, off_team = Home, def_team = Away, league = Country, match_id) |>\n  mutate(is_home = 1)\n\naway_goals <- big5 |>\n  select(n_goals = AwayGoals, xG = Away_xG, off_team = Away, def_team = Home, league = Country, match_id) |>\n  mutate(is_home = 0)\n\ngoals <- home_goals |>\n  bind_rows(away_goals)\n  \n# write_csv(goals, \"goals.csv\")  \n```\n:::",
    "supporting": [
      "15-glm_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}